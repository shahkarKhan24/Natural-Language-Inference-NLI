{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahkarKhan24/Natural-Language-Inference-NLI/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxFwyNofBM4K",
        "outputId": "149fa468-df85-4284-ad44-0650abb0ee9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\shahk\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (1.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from accelerate) (22.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from accelerate) (5.9.4)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from accelerate) (5.4.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from accelerate) (2.2.2+cu121)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from accelerate) (0.23.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
            "Requirement already satisfied: requests in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub->accelerate) (4.64.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shahk\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub->accelerate) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shahk\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub->accelerate) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shahk\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub->accelerate) (2022.9.24)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "   ---------------------------------------- 0.0/309.4 kB ? eta -:--:--\n",
            "   ------------------------------ --------- 235.5/309.4 kB 7.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 309.4/309.4 kB 4.7 MB/s eta 0:00:00\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.31.0\n",
            "Requirement already satisfied: datasets in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.19.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\shahk\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (1.23.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.5.2)\n",
            "Requirement already satisfied: requests>=2.32.1 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2023.12.2)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.23.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (22.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (5.4.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\shahk\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.8.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.1->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shahk\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.32.1->datasets) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shahk\\appdata\\roaming\\python\\python39\\site-packages (from requests>=2.32.1->datasets) (2022.9.24)\n",
            "Requirement already satisfied: colorama in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\shahk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngtwr9aNBM4Q",
        "outputId": "43609d70-8788-4c3e-848f-16263426027e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shahk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from typing import Dict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datasets import load_dataset, load_metric\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import roc_auc_score, hamming_loss\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DistilBertForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    AutoTokenizer,\n",
        "    EvalPrediction,\n",
        "    DistilBertConfig,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        "    TrainingArguments,\n",
        "    set_seed,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2rnn2kNBM4T",
        "outputId": "ddc7bfe4-7a25-4b13-9748-a0e895522584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
            "        num_rows: 51086\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
            "        num_rows: 2288\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
            "        num_rows: 2287\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "dataset = load_dataset(\"tommasobonomo/sem_augmented_fever_nli\")\n",
        "# View the dataset\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "royxvn7WBM4U",
        "outputId": "e475b435-b7ca-4d0a-fad2-e594d79c904c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': '150448', 'premise': \"Roman Atwood . He is best known for his vlogs , where he posts updates about his life on a daily basis . His vlogging channel , `` RomanAtwoodVlogs '' , has a total of 3.3 billion views and 11.9 million subscribers . He also has another YouTube channel called `` RomanAtwood '' , where he posts pranks .\", 'hypothesis': 'Roman Atwood is a content creator.', 'label': 'ENTAILMENT', 'wsd': {'premise': [{'index': 0, 'text': 'Roman', 'pos': 'ADJ', 'lemma': 'roman', 'bnSynsetId': 'bn:00109913a', 'wnSynsetOffset': '2921569a', 'nltkSynset': 'roman.a.01'}, {'index': 1, 'text': 'Atwood', 'pos': 'PROPN', 'lemma': 'Atwood', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 2, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 3, 'text': 'He', 'pos': 'PRON', 'lemma': 'he', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 4, 'text': 'is', 'pos': 'AUX', 'lemma': 'be', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 5, 'text': 'best', 'pos': 'ADV', 'lemma': 'well', 'bnSynsetId': 'bn:00117603r', 'wnSynsetOffset': '12779r', 'nltkSynset': 'well.r.02'}, {'index': 6, 'text': 'known', 'pos': 'VERB', 'lemma': 'know', 'bnSynsetId': 'bn:00090143v', 'wnSynsetOffset': '594337v', 'nltkSynset': 'know.v.04'}, {'index': 7, 'text': 'for', 'pos': 'ADP', 'lemma': 'for', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 8, 'text': 'his', 'pos': 'PRON', 'lemma': 'his', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 9, 'text': 'vlogs', 'pos': 'NOUN', 'lemma': 'vlog', 'bnSynsetId': 'bn:00028604n', 'wnSynsetOffset': '7007945n', 'nltkSynset': 'play.n.01'}, {'index': 10, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 11, 'text': 'where', 'pos': 'SCONJ', 'lemma': 'where', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 12, 'text': 'he', 'pos': 'PRON', 'lemma': 'he', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 13, 'text': 'posts', 'pos': 'VERB', 'lemma': 'post', 'bnSynsetId': 'bn:00091876v', 'wnSynsetOffset': '991683v', 'nltkSynset': 'post.v.02'}, {'index': 14, 'text': 'updates', 'pos': 'NOUN', 'lemma': 'update', 'bnSynsetId': 'bn:00079238n', 'wnSynsetOffset': '6643303n', 'nltkSynset': 'update.n.01'}, {'index': 15, 'text': 'about', 'pos': 'ADP', 'lemma': 'about', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 16, 'text': 'his', 'pos': 'PRON', 'lemma': 'his', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 17, 'text': 'life', 'pos': 'NOUN', 'lemma': 'life', 'bnSynsetId': 'bn:00051045n', 'wnSynsetOffset': '13963192n', 'nltkSynset': 'life.n.01'}, {'index': 18, 'text': 'on', 'pos': 'ADP', 'lemma': 'on', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 19, 'text': 'a', 'pos': 'DET', 'lemma': 'a', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 20, 'text': 'daily', 'pos': 'ADJ', 'lemma': 'daily', 'bnSynsetId': 'bn:00100875a', 'wnSynsetOffset': '1968165a', 'nltkSynset': 'daily.s.01'}, {'index': 21, 'text': 'basis', 'pos': 'NOUN', 'lemma': 'basis', 'bnSynsetId': 'bn:00008870n', 'wnSynsetOffset': '13790912n', 'nltkSynset': 'footing.n.02'}, {'index': 22, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 23, 'text': 'His', 'pos': 'PRON', 'lemma': 'his', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 24, 'text': 'vlogging', 'pos': 'VERB', 'lemma': 'vlogge', 'bnSynsetId': 'bn:00090000v', 'wnSynsetOffset': '672277v', 'nltkSynset': 'judge.v.01'}, {'index': 25, 'text': 'channel', 'pos': 'NOUN', 'lemma': 'channel', 'bnSynsetId': 'bn:00017686n', 'wnSynsetOffset': '3006398n', 'nltkSynset': 'channel.n.07'}, {'index': 26, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 27, 'text': '`', 'pos': 'PUNCT', 'lemma': '`', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 28, 'text': '`', 'pos': 'PUNCT', 'lemma': '`', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 29, 'text': 'RomanAtwoodVlogs', 'pos': 'X', 'lemma': 'romanatwoodvlogs', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 30, 'text': \"''\", 'pos': 'PUNCT', 'lemma': \"''\", 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 31, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 32, 'text': 'has', 'pos': 'AUX', 'lemma': 'have', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 33, 'text': 'a', 'pos': 'DET', 'lemma': 'a', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 34, 'text': 'total', 'pos': 'NOUN', 'lemma': 'total', 'bnSynsetId': 'bn:00002008n', 'wnSynsetOffset': '4353803n', 'nltkSynset': 'sum.n.05'}, {'index': 35, 'text': 'of', 'pos': 'ADP', 'lemma': 'of', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 36, 'text': '3.3', 'pos': 'NUM', 'lemma': '3.3', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 37, 'text': 'billion', 'pos': 'NUM', 'lemma': 'billion', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 38, 'text': 'views', 'pos': 'NOUN', 'lemma': 'view', 'bnSynsetId': 'bn:00071511n', 'wnSynsetOffset': '881649n', 'nltkSynset': 'view.n.03'}, {'index': 39, 'text': 'and', 'pos': 'CCONJ', 'lemma': 'and', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 40, 'text': '11.9', 'pos': 'NUM', 'lemma': '11.9', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 41, 'text': 'million', 'pos': 'NUM', 'lemma': 'million', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 42, 'text': 'subscribers', 'pos': 'NOUN', 'lemma': 'subscriber', 'bnSynsetId': 'bn:00066366n', 'wnSynsetOffset': '10670483n', 'nltkSynset': 'subscriber.n.02'}, {'index': 43, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 44, 'text': 'He', 'pos': 'PRON', 'lemma': 'he', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 45, 'text': 'also', 'pos': 'ADV', 'lemma': 'also', 'bnSynsetId': 'bn:00114246r', 'wnSynsetOffset': '47534r', 'nltkSynset': 'besides.r.02'}, {'index': 46, 'text': 'has', 'pos': 'AUX', 'lemma': 'have', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 47, 'text': 'another', 'pos': 'DET', 'lemma': 'another', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 48, 'text': 'YouTube', 'pos': 'PROPN', 'lemma': 'YouTube', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 49, 'text': 'channel', 'pos': 'NOUN', 'lemma': 'channel', 'bnSynsetId': 'bn:00015144n', 'wnSynsetOffset': '5250659n', 'nltkSynset': 'duct.n.01'}, {'index': 50, 'text': 'called', 'pos': 'VERB', 'lemma': 'call', 'bnSynsetId': 'bn:00084385v', 'wnSynsetOffset': '1028748v', 'nltkSynset': 'name.v.01'}, {'index': 51, 'text': '`', 'pos': 'PUNCT', 'lemma': '`', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 52, 'text': '`', 'pos': 'PUNCT', 'lemma': '`', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 53, 'text': 'RomanAtwood', 'pos': 'PROPN', 'lemma': 'RomanAtwood', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 54, 'text': \"''\", 'pos': 'PUNCT', 'lemma': \"''\", 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 55, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 56, 'text': 'where', 'pos': 'SCONJ', 'lemma': 'where', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 57, 'text': 'he', 'pos': 'PRON', 'lemma': 'he', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 58, 'text': 'posts', 'pos': 'VERB', 'lemma': 'post', 'bnSynsetId': 'bn:00091876v', 'wnSynsetOffset': '991683v', 'nltkSynset': 'post.v.02'}, {'index': 59, 'text': 'pranks', 'pos': 'NOUN', 'lemma': 'prank', 'bnSynsetId': 'bn:00004630n', 'wnSynsetOffset': '427580n', 'nltkSynset': 'antic.n.01'}, {'index': 60, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}], 'hypothesis': [{'index': 0, 'text': 'Roman', 'pos': 'PROPN', 'lemma': 'Roman', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 1, 'text': 'Atwood', 'pos': 'PROPN', 'lemma': 'Atwood', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 2, 'text': 'is', 'pos': 'AUX', 'lemma': 'be', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 3, 'text': 'a', 'pos': 'DET', 'lemma': 'a', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 4, 'text': 'content', 'pos': 'ADJ', 'lemma': 'content', 'bnSynsetId': 'bn:00100364a', 'wnSynsetOffset': '588797a', 'nltkSynset': 'contented.a.01'}, {'index': 5, 'text': 'creator', 'pos': 'NOUN', 'lemma': 'creator', 'bnSynsetId': 'bn:00023660n', 'wnSynsetOffset': '9614315n', 'nltkSynset': 'creator.n.02'}, {'index': 6, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}]}, 'srl': {'premise': {'tokens': [{'index': 0, 'rawText': 'Roman'}, {'index': 1, 'rawText': 'Atwood'}, {'index': 2, 'rawText': '.'}, {'index': 3, 'rawText': 'He'}, {'index': 4, 'rawText': 'is'}, {'index': 5, 'rawText': 'best'}, {'index': 6, 'rawText': 'known'}, {'index': 7, 'rawText': 'for'}, {'index': 8, 'rawText': 'his'}, {'index': 9, 'rawText': 'vlogs'}, {'index': 10, 'rawText': ','}, {'index': 11, 'rawText': 'where'}, {'index': 12, 'rawText': 'he'}, {'index': 13, 'rawText': 'posts'}, {'index': 14, 'rawText': 'updates'}, {'index': 15, 'rawText': 'about'}, {'index': 16, 'rawText': 'his'}, {'index': 17, 'rawText': 'life'}, {'index': 18, 'rawText': 'on'}, {'index': 19, 'rawText': 'a'}, {'index': 20, 'rawText': 'daily'}, {'index': 21, 'rawText': 'basis'}, {'index': 22, 'rawText': '.'}, {'index': 23, 'rawText': 'His'}, {'index': 24, 'rawText': 'vlogging'}, {'index': 25, 'rawText': 'channel'}, {'index': 26, 'rawText': ','}, {'index': 27, 'rawText': '`'}, {'index': 28, 'rawText': '`'}, {'index': 29, 'rawText': 'RomanAtwoodVlogs'}, {'index': 30, 'rawText': \"''\"}, {'index': 31, 'rawText': ','}, {'index': 32, 'rawText': 'has'}, {'index': 33, 'rawText': 'a'}, {'index': 34, 'rawText': 'total'}, {'index': 35, 'rawText': 'of'}, {'index': 36, 'rawText': '3.3'}, {'index': 37, 'rawText': 'billion'}, {'index': 38, 'rawText': 'views'}, {'index': 39, 'rawText': 'and'}, {'index': 40, 'rawText': '11.9'}, {'index': 41, 'rawText': 'million'}, {'index': 42, 'rawText': 'subscribers'}, {'index': 43, 'rawText': '.'}, {'index': 44, 'rawText': 'He'}, {'index': 45, 'rawText': 'also'}, {'index': 46, 'rawText': 'has'}, {'index': 47, 'rawText': 'another'}, {'index': 48, 'rawText': 'YouTube'}, {'index': 49, 'rawText': 'channel'}, {'index': 50, 'rawText': 'called'}, {'index': 51, 'rawText': '`'}, {'index': 52, 'rawText': '`'}, {'index': 53, 'rawText': 'RomanAtwood'}, {'index': 54, 'rawText': \"''\"}, {'index': 55, 'rawText': ','}, {'index': 56, 'rawText': 'where'}, {'index': 57, 'rawText': 'he'}, {'index': 58, 'rawText': 'posts'}, {'index': 59, 'rawText': 'pranks'}, {'index': 60, 'rawText': '.'}], 'annotations': [{'tokenIndex': 4, 'verbatlas': {'frameName': 'COPULA', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [3, 4]}, {'role': 'Attribute', 'score': 1.0, 'span': [5, 22]}]}, 'englishPropbank': {'frameName': 'be.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [3, 4]}, {'role': 'ARG2', 'score': 1.0, 'span': [5, 22]}]}}, {'tokenIndex': 6, 'verbatlas': {'frameName': 'KNOW', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [3, 4]}, {'role': 'Attribute', 'score': 1.0, 'span': [5, 6]}, {'role': 'Topic', 'score': 1.0, 'span': [7, 22]}]}, 'englishPropbank': {'frameName': 'know.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [3, 4]}, {'role': 'ARGM-MNR', 'score': 1.0, 'span': [5, 6]}, {'role': 'ARG2', 'score': 1.0, 'span': [7, 22]}]}}, {'tokenIndex': 13, 'verbatlas': {'frameName': 'RECORD', 'roles': [{'role': 'Location', 'score': 1.0, 'span': [8, 10]}, {'role': 'Agent', 'score': 1.0, 'span': [12, 13]}, {'role': 'Theme', 'score': 1.0, 'span': [14, 18]}, {'role': 'Time', 'score': 1.0, 'span': [18, 22]}]}, 'englishPropbank': {'frameName': 'post.01', 'roles': [{'role': 'ARGM-LOC', 'score': 1.0, 'span': [8, 10]}, {'role': 'R-ARGM-LOC', 'score': 1.0, 'span': [11, 12]}, {'role': 'ARG0', 'score': 1.0, 'span': [12, 13]}, {'role': 'ARG1', 'score': 1.0, 'span': [14, 18]}, {'role': 'ARGM-TMP', 'score': 1.0, 'span': [18, 22]}]}}, {'tokenIndex': 32, 'verbatlas': {'frameName': 'EXIST-WITH-FEATURE', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [23, 32]}, {'role': 'Attribute', 'score': 1.0, 'span': [33, 43]}]}, 'englishPropbank': {'frameName': 'have.03', 'roles': [{'role': 'ARG0', 'score': 1.0, 'span': [23, 32]}, {'role': 'ARG1', 'score': 1.0, 'span': [33, 43]}]}}, {'tokenIndex': 46, 'verbatlas': {'frameName': 'EXIST-WITH-FEATURE', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [44, 45]}, {'role': 'Attribute', 'score': 1.0, 'span': [47, 60]}]}, 'englishPropbank': {'frameName': 'have.03', 'roles': [{'role': 'ARG0', 'score': 1.0, 'span': [44, 45]}, {'role': 'ARGM-DIS', 'score': 1.0, 'span': [45, 46]}, {'role': 'ARG1', 'score': 1.0, 'span': [47, 60]}]}}, {'tokenIndex': 50, 'verbatlas': {'frameName': 'NAME', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [47, 50]}, {'role': 'Attribute', 'score': 1.0, 'span': [51, 55]}]}, 'englishPropbank': {'frameName': 'call.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [47, 50]}, {'role': 'ARG2', 'score': 1.0, 'span': [51, 55]}]}}, {'tokenIndex': 58, 'verbatlas': {'frameName': 'RECORD', 'roles': [{'role': 'Location', 'score': 1.0, 'span': [47, 55]}, {'role': 'Agent', 'score': 1.0, 'span': [57, 58]}, {'role': 'Theme', 'score': 1.0, 'span': [59, 60]}]}, 'englishPropbank': {'frameName': 'post.01', 'roles': [{'role': 'ARGM-LOC', 'score': 1.0, 'span': [47, 55]}, {'role': 'R-ARGM-LOC', 'score': 1.0, 'span': [56, 57]}, {'role': 'ARG0', 'score': 1.0, 'span': [57, 58]}, {'role': 'ARG1', 'score': 1.0, 'span': [59, 60]}]}}]}, 'hypothesis': {'tokens': [{'index': 0, 'rawText': 'Roman'}, {'index': 1, 'rawText': 'Atwood'}, {'index': 2, 'rawText': 'is'}, {'index': 3, 'rawText': 'a'}, {'index': 4, 'rawText': 'content'}, {'index': 5, 'rawText': 'creator'}, {'index': 6, 'rawText': '.'}], 'annotations': [{'tokenIndex': 2, 'verbatlas': {'frameName': 'COPULA', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [0, 2]}, {'role': 'Attribute', 'score': 1.0, 'span': [3, 6]}]}, 'englishPropbank': {'frameName': 'be.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [0, 2]}, {'role': 'ARG2', 'score': 1.0, 'span': [3, 6]}]}}]}}}\n"
          ]
        }
      ],
      "source": [
        "# Access the training data\n",
        "train_data = dataset['train']\n",
        "# Print the first example\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hye3Vg6SBM4V",
        "outputId": "7859991f-1d27-435a-e3d9-572cd5e79df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['part', 'cid', 'premise', 'hypothesis', 'label'],\n",
            "        num_rows: 337\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess the adversarial test set\n",
        "adversarial_test_dataset = load_dataset(\"iperbole/adversarial_fever_nli\")\n",
        "# View the dataset\n",
        "print(adversarial_test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlIw_OKjBM4W",
        "outputId": "d96216b1-56af-4070-bfa9-db9142ccc2ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\shahk\\AppData\\Local\\Temp\\ipykernel_9972\\2462315092.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  load_accuracy = load_metric(\"accuracy\",trust_remote_code=True)\n"
          ]
        }
      ],
      "source": [
        "# Metrics\n",
        "# Load metrics\n",
        "load_accuracy = load_metric(\"accuracy\",trust_remote_code=True)\n",
        "load_precision = load_metric(\"precision\",trust_remote_code=True)\n",
        "load_recall = load_metric(\"recall\",trust_remote_code=True)\n",
        "load_f1 = load_metric(\"f1\",trust_remote_code=True)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    precision = load_precision.compute(predictions=predictions, references=labels, average='weighted')[\"precision\"]\n",
        "    recall = load_recall.compute(predictions=predictions, references=labels, average='weighted')[\"recall\"]\n",
        "    f1 = load_f1.compute(predictions=predictions, references=labels, average='weighted')[\"f1\"]\n",
        "    # Convert logits to probabilities\n",
        "    probabilities = softmax(logits, axis=1)\n",
        "\n",
        "    # Compute additional metrics\n",
        "    roc_auc = roc_auc_score(labels, probabilities, multi_class='ovr')\n",
        "    hamming = hamming_loss(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"hamming_loss\": hamming,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y55bHVntBM4X",
        "outputId": "da56b3a6-b71f-49ff-fd90-1a7c1665cb6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrAbzONBM4Y"
      },
      "source": [
        "# Roberta model\n",
        "Training model # 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWflA327BM4b",
        "outputId": "e5f06034-11ee-4742-f70f-753c5877f7c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "language_model_name = \"roberta-base\"\n",
        "# this GPU should be enough for this task to handle 32 samples per batch\n",
        "batch_size = 16\n",
        "# optim\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 0.001 # we could use e.g. 0.01 in case of very low and very high amount of data for regularization\n",
        "# training\n",
        "epochs = 1\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "set_seed(42)\n",
        "\n",
        "## Initialize the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(language_model_name,\n",
        "                                                                   ignore_mismatched_sizes=True,\n",
        "                                                                   output_attentions=False, output_hidden_states=False,\n",
        "                                                                   num_labels=3) # number of the classes\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(language_model_name)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyPqVo2IBM4c"
      },
      "outputs": [],
      "source": [
        "def encode_labels(example):\n",
        "    label_map = {\"ENTAILMENT\": 0, \"CONTRADICTION\": 1, \"NEUTRAL\": 2}\n",
        "    example[\"label\"] = label_map[example[\"label\"]]\n",
        "    return example\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['premise'], examples['hypothesis'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "# def preprocess_function(examples):\n",
        "#     inputs = [\"[CLS] \" + premise + \" [SEP] \" + hypothesis for premise, hypothesis in zip(examples['premise'], examples['hypothesis'])]\n",
        "#     return tokenizer(inputs, truncation=True, padding='max_length', max_length=128, add_special_tokens=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCtj84kMBM4d",
        "outputId": "a00e7dda-1d74-4298-e2b1-ab4e9870b9a4",
        "colab": {
          "referenced_widgets": [
            "70b5df4ee4014d4794d37eb70a13e604",
            "e7cd7af016504efaa76c1b631aaf98c7",
            "6ba41eea2d324c199fae5b7ff2e855e5",
            "4e1607a0ce424d87810aa8e78ff5fb8d"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70b5df4ee4014d4794d37eb70a13e604",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2288 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7cd7af016504efaa76c1b631aaf98c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/51086 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ba41eea2d324c199fae5b7ff2e855e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2288 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e1607a0ce424d87810aa8e78ff5fb8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2287 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.map(encode_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-WqMhtBBM4e"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",                    # output directory [Mandatory]\n",
        "    num_train_epochs=1,                      # total number of training epochs\n",
        "    per_device_train_batch_size=batch_size,       # batch size per device during training\n",
        "    warmup_steps=500,                             # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=weight_decay,                    # strength of weight decay\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=learning_rate                   # learning rate\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIkIw4HLBM4e",
        "outputId": "6a4d83eb-5682-4e36-c71c-fa5e6ce54ecc",
        "colab": {
          "referenced_widgets": [
            "c8be4f48fc924b9d88092821f8561385"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshahkarkhan24\u001b[0m (\u001b[33mshahkar\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.17.4 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>d:\\Sapienza\\15. Multi-Lingual Natural Language Processing\\HW-02\\wandb\\run-20240714_062814-gejgikk1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/shahkar/huggingface/runs/gejgikk1\" target=\"_blank\">./results</a></strong> to <a href=\"https://wandb.ai/shahkar/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8be4f48fc924b9d88092821f8561385",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3193 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7615, 'grad_norm': 21.145954132080078, 'learning_rate': 0.0001, 'epoch': 0.16}\n",
            "{'loss': 0.6901, 'grad_norm': 10.859151840209961, 'learning_rate': 8.143334571110286e-05, 'epoch': 0.31}\n",
            "{'loss': 0.6637, 'grad_norm': 4.032456398010254, 'learning_rate': 6.286669142220572e-05, 'epoch': 0.47}\n",
            "{'loss': 0.5839, 'grad_norm': 7.356015205383301, 'learning_rate': 4.430003713330858e-05, 'epoch': 0.63}\n",
            "{'loss': 0.5216, 'grad_norm': 7.082505702972412, 'learning_rate': 2.5733382844411435e-05, 'epoch': 0.78}\n",
            "{'loss': 0.4884, 'grad_norm': 5.406497001647949, 'learning_rate': 7.166728555514296e-06, 'epoch': 0.94}\n",
            "{'train_runtime': 1707.7554, 'train_samples_per_second': 29.914, 'train_steps_per_second': 1.87, 'train_loss': 0.6079318712319919, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3193, training_loss=0.6079318712319919, metrics={'train_runtime': 1707.7554, 'train_samples_per_second': 29.914, 'train_steps_per_second': 1.87, 'total_flos': 3360353014513152.0, 'train_loss': 0.6079318712319919, 'epoch': 1.0})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpOqdUQ2BM4f"
      },
      "source": [
        "Evaluaating roberta model on standard test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXxTbjEEBM4g",
        "outputId": "4e6e94ff-72b2-4563-84fa-fca9e857d2fd",
        "colab": {
          "referenced_widgets": [
            "89229a40932145e994317969075b2c72"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89229a40932145e994317969075b2c72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/286 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Test Set Results: {'eval_loss': 0.8490660190582275, 'eval_accuracy': 0.6943594228246611, 'eval_precision': 0.6879176651634599, 'eval_recall': 0.6943594228246611, 'eval_f1': 0.6818675986758914, 'eval_roc_auc': 0.843863808216641, 'eval_hamming_loss': 0.3056405771753389, 'eval_runtime': 25.6202, 'eval_samples_per_second': 89.266, 'eval_steps_per_second': 11.163, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "results_standard = trainer.evaluate(tokenized_datasets['test'])\n",
        "print(f\"Standard Test Set Results: {results_standard}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68SFExFfBM4h"
      },
      "source": [
        "Evaluaating roberta model on adverserial testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4uUxehxBM4h",
        "outputId": "717bef33-1ecd-4555-d156-d54df1a4083f",
        "colab": {
          "referenced_widgets": [
            "f6b0b000eb074bb4bfc5098e68d85929"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6b0b000eb074bb4bfc5098e68d85929",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/43 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adversarial Test Set Results: {'eval_test_loss': 1.3014122247695923, 'eval_test_accuracy': 0.5103857566765578, 'eval_test_precision': 0.516193648089156, 'eval_test_recall': 0.5103857566765578, 'eval_test_f1': 0.5101830483923316, 'eval_test_roc_auc': 0.6715665865686232, 'eval_test_hamming_loss': 0.4896142433234421, 'eval_test_runtime': 3.9488, 'eval_test_samples_per_second': 85.342, 'eval_test_steps_per_second': 10.889, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "adversarial_tokenized = adversarial_test_dataset.map(preprocess_function, batched=True)\n",
        "adversarial_tokenized = adversarial_tokenized.map(encode_labels)\n",
        "# Evaluate on the adversarial test set\n",
        "results_adversarial = trainer.evaluate(adversarial_tokenized)\n",
        "print(f\"Adversarial Test Set Results: {results_adversarial}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULkFNVFBBM4i"
      },
      "source": [
        "# Distilbert_uncased\n",
        "Training model # 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s01xbRvMBM4i",
        "outputId": "ab813362-f4e8-401c-923b-9d19f34e4fa6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "language_model_name = \"distilbert-base-uncased\"\n",
        "# Initialize the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(language_model_name,\n",
        "                                                                   ignore_mismatched_sizes=True,\n",
        "                                                                   output_attentions=False, output_hidden_states=False,\n",
        "                                                                   num_labels=3) # number of the classes\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(language_model_name)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfhj66WYBM4j"
      },
      "outputs": [],
      "source": [
        "def encode_labels(example):\n",
        "    label_map = {\"ENTAILMENT\": 0, \"CONTRADICTION\": 1, \"NEUTRAL\": 2}\n",
        "    example[\"label\"] = label_map[example[\"label\"]]\n",
        "    return example\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['premise'], examples['hypothesis'], truncation=True, padding='max_length', max_length=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9739_mpBM4j"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.map(encode_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Ieq2ORBM4k"
      },
      "source": [
        "Training arguments remains the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxFoSy3sBM4k",
        "outputId": "8ea39c9c-d26d-4114-fd30-1642143a8c09",
        "colab": {
          "referenced_widgets": [
            "e5122be0443e4d919d130506102e453c"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5122be0443e4d919d130506102e453c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3193 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6934, 'grad_norm': 7.663567543029785, 'learning_rate': 0.0001, 'epoch': 0.16}\n",
            "{'loss': 0.5563, 'grad_norm': 4.596882343292236, 'learning_rate': 8.143334571110286e-05, 'epoch': 0.31}\n",
            "{'loss': 0.5004, 'grad_norm': 2.569326400756836, 'learning_rate': 6.286669142220572e-05, 'epoch': 0.47}\n",
            "{'loss': 0.4751, 'grad_norm': 7.720330238342285, 'learning_rate': 4.430003713330858e-05, 'epoch': 0.63}\n",
            "{'loss': 0.4518, 'grad_norm': 2.6637659072875977, 'learning_rate': 2.5733382844411435e-05, 'epoch': 0.78}\n",
            "{'loss': 0.4457, 'grad_norm': 5.572751522064209, 'learning_rate': 7.166728555514296e-06, 'epoch': 0.94}\n",
            "{'train_runtime': 870.0749, 'train_samples_per_second': 58.714, 'train_steps_per_second': 3.67, 'train_loss': 0.5137281313309877, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3193, training_loss=0.5137281313309877, metrics={'train_runtime': 870.0749, 'train_samples_per_second': 58.714, 'train_steps_per_second': 3.67, 'total_flos': 1691837552918016.0, 'train_loss': 0.5137281313309877, 'epoch': 1.0})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkMxWy9FBM4l"
      },
      "source": [
        "Evaluating DistilBert model on standard test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wajt4EYFBM4l",
        "outputId": "dcd0628e-d3a1-4d00-9efc-e11faa6a1cda",
        "colab": {
          "referenced_widgets": [
            "d1ea301d41df4aa19b44413e2e420712"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1ea301d41df4aa19b44413e2e420712",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/286 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Test Set Results: {'eval_loss': 0.7932063937187195, 'eval_accuracy': 0.7022299956274596, 'eval_precision': 0.7012149224357939, 'eval_recall': 0.7022299956274596, 'eval_f1': 0.6923819271909458, 'eval_roc_auc': 0.8546023759794337, 'eval_hamming_loss': 0.2977700043725404, 'eval_runtime': 13.8056, 'eval_samples_per_second': 165.657, 'eval_steps_per_second': 20.716, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "results_standard = trainer.evaluate(tokenized_datasets['test'])\n",
        "print(f\"Standard Test Set Results: {results_standard}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHzutMXLBM4m"
      },
      "source": [
        "Evaluating DistilBert model on adverserial testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx7oUxdhBM4m",
        "outputId": "2a25f901-c5fe-426c-f9b5-e50a1aea8261",
        "colab": {
          "referenced_widgets": [
            "0b4a46fbc5e141f59da1b91126e42ad5"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b4a46fbc5e141f59da1b91126e42ad5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/43 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adversarial Test Set Results: {'eval_test_loss': 1.3519256114959717, 'eval_test_accuracy': 0.516320474777448, 'eval_test_precision': 0.5411160930290758, 'eval_test_recall': 0.516320474777448, 'eval_test_f1': 0.518962524502693, 'eval_test_roc_auc': 0.6570465309504344, 'eval_test_hamming_loss': 0.4836795252225519, 'eval_test_runtime': 2.2066, 'eval_test_samples_per_second': 152.724, 'eval_test_steps_per_second': 19.487, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "adversarial_tokenized = adversarial_test_dataset.map(preprocess_function, batched=True)\n",
        "adversarial_tokenized = adversarial_tokenized.map(encode_labels)\n",
        "# Evaluate on the adversarial test set\n",
        "results_adversarial = trainer.evaluate(adversarial_tokenized)\n",
        "print(f\"Adversarial Test Set Results: {results_adversarial}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rds9XjEwBM4n"
      },
      "source": [
        "Both model was giving almost same result on standard test set and adversarial set but â€œroberta â€ model was taking way more time during training, each epoch was taking almost 32 minutes while  â€œdistilbertâ€ model was taking about 24 minutes. So, we selected â€œdistilbertâ€ model afterward for further experimentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhjKN2mTBM4o"
      },
      "source": [
        "# Introducing Achitectural Changes to above model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7IwIGP7BM4o"
      },
      "source": [
        "To introduce meaningful architectural changes to my model for the NLI task, I consider several approaches, such as:\n",
        "\n",
        "Integrating Sentence-Level Embeddings:Using pre-trained sentence embeddings to enhance the input representation.\n",
        "\n",
        "Using Attention Mechanisms:Adding an attention layer to focus on important parts of the input.\n",
        "\n",
        "Combining Multiple Pre-trained Models:\n",
        "Using two different models and combining their outputs.\n",
        "\n",
        "below is the implementation of a model that integrates sentence-level embeddings and uses an attention mechanism. We'll use sentence embeddings from a pre-trained model like sentence-transformers and an attention mechanism to enhance the model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqXjwKNFBM4p"
      },
      "source": [
        "# Model Output:\n",
        "\n",
        "The model processes the input tokens (input_ids) and their attention masks (attention_mask).\n",
        "It extracts the [CLS] token representation from DistilBERT, which is typically used for classification tasks.\n",
        "Projection Layer:\n",
        "\n",
        "The [CLS] token output (768 dimensions) is projected down to 384 dimensions to match the size of the sentence embeddings.\n",
        "Sentence Embeddings:\n",
        "\n",
        "The input sentences are decoded from token IDs back into text.\n",
        "Sentence embeddings are generated using the SentenceTransformer model. These embeddings capture the overall meaning of the sentences.\n",
        "Attention Mechanism:\n",
        "\n",
        "The projected output from DistilBERT and the sentence embeddings are passed through a multi-head attention layer.\n",
        "The attention mechanism helps the model focus on different parts of the sentence embeddings, potentially capturing more useful information.\n",
        "Combining Outputs:\n",
        "\n",
        "The outputs from the attention layer and the projected DistilBERT output are concatenated.\n",
        "The combined output (768 dimensions) is passed through the final classifier layer to produce logits for classification.\n",
        "Loss Calculation:\n",
        "\n",
        "If labels are provided, the model calculates the cross-entropy loss between the predicted logits and the true labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4o-9APLqBM4q",
        "outputId": "15a75c0c-d145-42af-b88c-376c28e9003c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shahk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Access the training data\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# Model Parameters\n",
        "language_model_name = \"distilbert-base-uncased\"\n",
        "sentence_embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "# Training Arguments\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "# learning_rate = 1e-5\n",
        "weight_decay = 0.001\n",
        "# weight_decay = 0.01\n",
        "epochs = 1\n",
        "set_seed(42)\n",
        "# Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(language_model_name)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)#Pads sequences to the same length in a batch.\n",
        "sentence_embedding_model = SentenceTransformer(sentence_embedding_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDFhQbvlBM4r"
      },
      "outputs": [],
      "source": [
        "# Custom model with sentence embeddings and attention\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, base_model_name, sentence_embedding_model, num_labels):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.base_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "            base_model_name,\n",
        "            num_labels=num_labels\n",
        "        )\n",
        "        self.sentence_embedding_model = sentence_embedding_model\n",
        "        self.projection = nn.Linear(self.base_model.config.hidden_size, 384)  # Project DistilBERT output to match sentence embeddings\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=384, num_heads=4)\n",
        "        self.dropout = nn.Dropout(0.3)  # Dropout for regularization\n",
        "        self.classifier = nn.Linear(384 + 384, num_labels)  # Combine both outputs\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        # Get DistilBERT outputs\n",
        "        outputs = self.base_model.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[0][:, 0]  # Take the [CLS] token representation\n",
        "\n",
        "        # Project DistilBERT output\n",
        "        projected_output = self.projection(pooled_output)\n",
        "\n",
        "        # Get sentence embeddings\n",
        "        with torch.no_grad():\n",
        "            sentences = tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
        "            sentence_embeddings = torch.tensor(self.sentence_embedding_model.encode(sentences)).to(input_ids.device)\n",
        "\n",
        "        # Apply attention mechanism\n",
        "        attn_output, _ = self.attention(projected_output.unsqueeze(0), sentence_embeddings.unsqueeze(0), sentence_embeddings.unsqueeze(0))\n",
        "        attn_output = attn_output.squeeze(0)\n",
        "\n",
        "        # Combine outputs and apply dropout\n",
        "        combined_output = torch.cat((projected_output, attn_output), dim=1)\n",
        "        combined_output = self.dropout(combined_output)\n",
        "        logits = self.classifier(combined_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.base_model.num_labels), labels.view(-1))\n",
        "\n",
        "        return {'loss': loss, 'logits': logits}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQCcGH9oBM4s",
        "outputId": "7da4fc21-938c-4525-e92b-075de7ac059c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Initialize the custom model\n",
        "model = CustomModel(language_model_name, sentence_embedding_model, num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga9A7cY3BM4t",
        "outputId": "d0d9f910-2401-487a-eba6-6428c1cf5608",
        "colab": {
          "referenced_widgets": [
            "3d8a945fce694d5482836a7921e7800d"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d8a945fce694d5482836a7921e7800d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6386 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shahk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7016, 'grad_norm': 10.575435638427734, 'learning_rate': 0.0001, 'epoch': 0.16}\n",
            "{'loss': 0.5622, 'grad_norm': 2.985837936401367, 'learning_rate': 9.150526673462454e-05, 'epoch': 0.31}\n",
            "{'loss': 0.5176, 'grad_norm': 4.099152088165283, 'learning_rate': 8.301053346924907e-05, 'epoch': 0.47}\n",
            "{'loss': 0.4995, 'grad_norm': 6.388758659362793, 'learning_rate': 7.45158002038736e-05, 'epoch': 0.63}\n",
            "{'loss': 0.4755, 'grad_norm': 5.958062171936035, 'learning_rate': 6.602106693849813e-05, 'epoch': 0.78}\n",
            "{'loss': 0.4857, 'grad_norm': 5.321105480194092, 'learning_rate': 5.7526333673122665e-05, 'epoch': 0.94}\n",
            "{'loss': 0.3936, 'grad_norm': 2.9125046730041504, 'learning_rate': 4.90316004077472e-05, 'epoch': 1.1}\n",
            "{'loss': 0.3617, 'grad_norm': 1.0651590824127197, 'learning_rate': 4.0536867142371735e-05, 'epoch': 1.25}\n",
            "{'loss': 0.3481, 'grad_norm': 2.4638373851776123, 'learning_rate': 3.204213387699626e-05, 'epoch': 1.41}\n",
            "{'loss': 0.3569, 'grad_norm': 5.123266696929932, 'learning_rate': 2.3547400611620795e-05, 'epoch': 1.57}\n",
            "{'loss': 0.3284, 'grad_norm': 4.452888488769531, 'learning_rate': 1.5052667346245328e-05, 'epoch': 1.72}\n",
            "{'loss': 0.3192, 'grad_norm': 16.210777282714844, 'learning_rate': 6.557934080869861e-06, 'epoch': 1.88}\n",
            "{'train_runtime': 1970.1387, 'train_samples_per_second': 51.86, 'train_steps_per_second': 3.241, 'train_loss': 0.4373035735558314, 'epoch': 2.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6386, training_loss=0.4373035735558314, metrics={'train_runtime': 1970.1387, 'train_samples_per_second': 51.86, 'train_steps_per_second': 3.241, 'total_flos': 0.0, 'train_loss': 0.4373035735558314, 'epoch': 2.0})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",                    # output directory [Mandatory]\n",
        "    num_train_epochs=2,                      # total number of training epochs\n",
        "    per_device_train_batch_size=batch_size,       # batch size per device during training\n",
        "    warmup_steps=500,                             # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=weight_decay,                    # strength of weight decay\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=learning_rate                   # learning rate\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-Q3hN7mBM4u"
      },
      "source": [
        "Evaluating on standard testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIPrQ94UBM4v",
        "outputId": "efaba05d-42ef-4921-ba72-7df022960239",
        "colab": {
          "referenced_widgets": [
            "ad29aa83c9ba4397aeb888bf5df48cd6"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad29aa83c9ba4397aeb888bf5df48cd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/286 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Test Set Results: {'eval_loss': 0.8944422006607056, 'eval_accuracy': 0.7031045037166593, 'eval_precision': 0.7019789096954616, 'eval_recall': 0.7031045037166593, 'eval_f1': 0.6950522346776756, 'eval_roc_auc': 0.8559390820358278, 'eval_hamming_loss': 0.2968954962833406, 'eval_runtime': 18.9191, 'eval_samples_per_second': 120.883, 'eval_steps_per_second': 15.117, 'epoch': 2.0}\n"
          ]
        }
      ],
      "source": [
        "results_standard = trainer.evaluate(tokenized_datasets['test'])\n",
        "print(f\"Standard Test Set Results: {results_standard}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3eCK8q-BM4v",
        "outputId": "47a9e54b-4e49-48e6-d28e-c80f17eaf40c",
        "colab": {
          "referenced_widgets": [
            "64f64bc6218b429380bcc48765665c49"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64f64bc6218b429380bcc48765665c49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/43 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adversarial Test Set Results: {'eval_test_loss': 1.5860499143600464, 'eval_test_accuracy': 0.49851632047477745, 'eval_test_precision': 0.5114163504186483, 'eval_test_recall': 0.49851632047477745, 'eval_test_f1': 0.5004167917663728, 'eval_test_roc_auc': 0.6528492691464999, 'eval_test_hamming_loss': 0.5014836795252225, 'eval_test_runtime': 3.0677, 'eval_test_samples_per_second': 109.853, 'eval_test_steps_per_second': 14.017, 'epoch': 2.0}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on the adversarial test set\n",
        "results_adversarial = trainer.evaluate(adversarial_tokenized)\n",
        "print(f\"Adversarial Test Set Results: {results_adversarial}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn4Y0KaABM4w"
      },
      "source": [
        "<h2>Combining adverserial and Original dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bATnHEq4BM4z"
      },
      "source": [
        "In below cell it is being assumed that the adverserial dataset has been stored in the mentioned path and being loaded. refer the the data augmentation notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFHsS9ADBM40"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "Adverserial_Dataset = load_from_disk('adverserial_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTHMBrHyBM40",
        "outputId": "4da475b5-f5eb-44d0-c410-5a67a9eb1612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
            "        num_rows: 66086\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
            "        num_rows: 2288\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
            "        num_rows: 2287\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset, DatasetDict, concatenate_datasets\n",
        "\n",
        "# Combine the train set of the first dataset with the second dataset\n",
        "combined_train_dataset = concatenate_datasets([dataset['train'], Adverserial_Dataset])\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "shuffled_combined_train_dataset = combined_train_dataset.shuffle(seed=42)\n",
        "\n",
        "# Replace the train set in the first dataset with the shuffled combined dataset\n",
        "combined_dataset_dict = DatasetDict({\n",
        "    'train': shuffled_combined_train_dataset,\n",
        "    'validation': dataset['validation'],\n",
        "    'test': dataset['test']\n",
        "})\n",
        "\n",
        "print(combined_dataset_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz_yikLPBM41"
      },
      "source": [
        "# Training another model with Adverserial training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zg195NwnBM42",
        "outputId": "83fbd38f-8bb4-4628-e76e-2ce4e2f69f77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shahk\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Modify the configuration to set a custom dropout rate\n",
        "num_labels=3\n",
        "language_model_name = \"distilbert-base-uncased\"\n",
        "config = DistilBertConfig.from_pretrained(language_model_name)\n",
        "config.hidden_dropout_prob = 0.3  # Set your custom dropout rate here\n",
        "config.num_labels = num_labels\n",
        "config.output_attentions = False\n",
        "config.output_hidden_states = False\n",
        "# Initialize the model\n",
        "# Load model and tokenizer with modified configuration\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    language_model_name,\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(language_model_name,\n",
        "#                                                                    config=config,\n",
        "#                                                                    ignore_mismatched_sizes=True,\n",
        "#                                                                    output_attentions=False,\n",
        "#                                                                    output_hidden_states=False,\n",
        "#                                                                    num_labels=3) # number of the classes\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(language_model_name)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP3FZ2FVBM43"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = combined_dataset_dict.map(preprocess_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.map(encode_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DtLY4HCBM43"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "# optim\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 0.001 # we could use e.g. 0.01 in case of very low and very high amount of data for regularization\n",
        "# training\n",
        "epochs = 1\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz9ZmkbUBM44",
        "outputId": "4ecd7388-69d7-43bc-cc34-7aa165c2f9f7",
        "colab": {
          "referenced_widgets": [
            "57d2a84d435c4ca484d500cdd8c81bf9"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57d2a84d435c4ca484d500cdd8c81bf9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4131 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7201, 'grad_norm': 3.4628992080688477, 'learning_rate': 0.0001, 'epoch': 0.12}\n",
            "{'loss': 0.5949, 'grad_norm': 3.975820541381836, 'learning_rate': 8.622968879096668e-05, 'epoch': 0.24}\n",
            "{'loss': 0.541, 'grad_norm': 3.5909810066223145, 'learning_rate': 7.245937758193335e-05, 'epoch': 0.36}\n",
            "{'loss': 0.5128, 'grad_norm': 4.571284294128418, 'learning_rate': 5.868906637290003e-05, 'epoch': 0.48}\n",
            "{'loss': 0.4872, 'grad_norm': 4.745654106140137, 'learning_rate': 4.491875516386671e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4619, 'grad_norm': 3.651492118835449, 'learning_rate': 3.114844395483338e-05, 'epoch': 0.73}\n",
            "{'loss': 0.446, 'grad_norm': 26.286725997924805, 'learning_rate': 1.7378132745800055e-05, 'epoch': 0.85}\n",
            "{'loss': 0.4247, 'grad_norm': 5.264534950256348, 'learning_rate': 3.607821536766731e-06, 'epoch': 0.97}\n",
            "{'train_runtime': 1118.2704, 'train_samples_per_second': 59.097, 'train_steps_per_second': 3.694, 'train_loss': 0.5198253843057706, 'epoch': 1.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4131, training_loss=0.5198253843057706, metrics={'train_runtime': 1118.2704, 'train_samples_per_second': 59.097, 'train_steps_per_second': 3.694, 'total_flos': 2188599156758016.0, 'train_loss': 0.5198253843057706, 'epoch': 1.0})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",                    # output directory [Mandatory]\n",
        "    num_train_epochs=epochs,                      # total number of training epochs\n",
        "    per_device_train_batch_size=batch_size,       # batch size per device during training\n",
        "    warmup_steps=500,                             # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=weight_decay,                    # strength of weight decay\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=learning_rate                   # learning rate\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCxeCwrLBM45"
      },
      "source": [
        "Evaluating on standard testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXDwXQf8BM45",
        "outputId": "9010d00e-ba29-4fb2-a772-5c3b2a54a87c",
        "colab": {
          "referenced_widgets": [
            "256ae8db83494298a55d981788931d86"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "256ae8db83494298a55d981788931d86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/286 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Test Set Results: {'eval_loss': 0.8289945721626282, 'eval_accuracy': 0.6965456930476607, 'eval_precision': 0.7023926852096799, 'eval_recall': 0.6965456930476607, 'eval_f1': 0.6848846509973214, 'eval_roc_auc': 0.8562204991042014, 'eval_hamming_loss': 0.3034543069523393, 'eval_runtime': 13.3017, 'eval_samples_per_second': 171.933, 'eval_steps_per_second': 21.501, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "results_standard = trainer.evaluate(tokenized_datasets['test'])\n",
        "print(f\"Standard Test Set Results: {results_standard}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiKtUnLaBM46"
      },
      "source": [
        "Evaluating on Adverserial Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dH1j06BoBM46",
        "outputId": "d2077dfd-2256-492f-d99e-8800d342e5e9",
        "colab": {
          "referenced_widgets": [
            "003cb608262349c7a6f79b6b0f1dc72a"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "003cb608262349c7a6f79b6b0f1dc72a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/43 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adversarial Test Set Results: {'eval_test_loss': 1.4084587097167969, 'eval_test_accuracy': 0.5044510385756676, 'eval_test_precision': 0.5360963355484721, 'eval_test_recall': 0.5044510385756676, 'eval_test_f1': 0.5057083872521098, 'eval_test_roc_auc': 0.6579466121552624, 'eval_test_hamming_loss': 0.49554896142433236, 'eval_test_runtime': 2.056, 'eval_test_samples_per_second': 163.914, 'eval_test_steps_per_second': 20.915, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "adversarial_tokenized = adversarial_test_dataset.map(preprocess_function, batched=True)\n",
        "adversarial_tokenized = adversarial_tokenized.map(encode_labels)\n",
        "# Evaluate on the adversarial test set\n",
        "results_adversarial = trainer.evaluate(adversarial_tokenized)\n",
        "print(f\"Adversarial Test Set Results: {results_adversarial}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC6qzUtlBM47"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyX-df0KBM48"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v45U70FfBM48"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}